{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "### Problem Description\n",
    "<!-- the problem the software solves -->\n",
    "This library solves the computational technique of automatic differentiation: a process to compute derivatives numerically within accurate machine approximation. This task is also called algorithmic differentiation, computational differentiation, or auto-differentation.\n",
    "\n",
    "Computing derivatives can be an easy task for a human, simply apply a few rules here and there and some specific functional derivatives. If complexity is low, a human can compute a derivative in one step. A computer, however, runs computations one at a time (ignoring parallel computing), collecting the information about the small computations in memory. That is, calaulcations are made step by step, the result being applied to the subsequent computation needed in the grand scheme of computing the overall derivative. A computer must either be given the values to make a direct computation, or the values that allow it to perform minor computations with those values and aggregate them with elementary operations like multiplcation, division, addition, or subtraction.\n",
    "\n",
    "Many algorithms are *optimizational*, which requires the use such derivatives. When dealing with problems with more than one dimension, we must adapt the simple optimization problem into a multi-dimensional optimization problem. Derivatives and algorithms that use them are utilities, primaily used for their contribution to a bigger project rather than instrinsic value.\n",
    "\n",
    "### Motivations\n",
    "<!-- why it's important to solve that problem -->\n",
    "Optimization is everywhere today, as it aims to solve a problem according to some constraint to the best of its ability. Minimizing the error of a function for *machine learning* frequently requires multi-dimensional optimization. There are a few more specific examples listed below.\n",
    "\n",
    "- *Neural networks* require the adjustement of a vector of weights per layer, therefore requiring us to optimize with respect to some standard (function).\n",
    "- Using *hueristic artificial intelligence methods* like *hill climbing* or *partical swarm* require the adjustment of -- for example purposes -- a ball dropped into a plane and moved in the direction (x, y) that gets the ball to the target point the fastest. \n",
    "- Problems in *physics* and *material science* requires the analysis of functions that rely on time, position, speed, and other problem-specific metrics."
>>>>>>> 1f66644a733065ccbff33ad0e7696d371a95efe3
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "<!-- (Brief) give the essential ideas of mathematical ideas and concepts (e.g. the chain rule, the graph structure of calculations, elementary functions, etc) -->\n",
    "\n",
    "Automatic differentiation computes the derivative of a function by solving it as a collection of the derivatives of its components. These individual components are elementary functions, connected by known, simple operators. The purpose behind this separation is that the individual functions can be easily solved using pre-established rules. The automatic differentiator can then solve any function made up of these components. Automated differentiation uses the chain rule to split the given function into these elementary operators.\n",
    "\n",
    "<!-- \n",
    "Note: We should add a computation graph and notes about forward mode (and reverse mode?).\n",
    "Note: We should make a table(?) of all the accepted functions and their derivatives/how they will be used? ($ a+b $, $ a-b $, $ ab $, $ \\frac{a}{b} $, $ a^{b} $, $ sin(a) $, $ cos(a) $, $ tan(a) $, $ ln(a) $)\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage Guide\n",
    "\n",
    "<!-- How do you envision that a user will interact with your package? What should they import? How can they instantiate AD objects? -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Software Organization\n",
    "\n",
    "<!-- \n",
    "    What will the directory structure look like?\n",
    "    What modules do you plan on including? What is their basic functionality?\n",
    "    Where will your test suite live?\n",
    "    How will you distribute your package (e.g. PyPI with PEP517/518 or simply setuptools)?\n",
    "    Other considerations?\n",
    " -->\n",
    " \n",
    "### Directory Structure\n",
    "```\n",
    "|team23\n",
    "|—— docs\n",
    "|  |—— README.md\n",
    "|  |—— documentation\n",
    "|  |—— milestone1.ipynb\n",
    "|  |—— milestone2.ipynb\n",
    "|——LICENSE\n",
    "|——README.md\n",
    "|——src\n",
    "|  |—— __init__.py\n",
    "|  |——fad.py\n",
    "|——install\n",
    "|  |—— __init__.py\n",
    "|——tests\n",
    "|  |—— __init__.py\n",
    "```\n",
    "### Modules\n",
    "<!-- \n",
    "Note: What modules do you plan on including? What is their basic functionality?\n",
    " -->\n",
    "### Tests\n",
    "The test suite will be located in the tests directory in the package's root directory.\n",
    "### Distribution\n",
    "The package will be distributed using the Python Package Index, PyPI. It will also be available to be cloned through our team23 GitHub repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation\n",
    "\n",
    "### Foward-Mode AD\n",
    " <!-- \n",
    "    What are the core data structures?\n",
    "    What classes will you implement?\n",
    "    What method and name attributes will your classes have?\n",
    "    What external dependencies will you rely on?\n",
    "    How will you deal with elementary functions like sin, sqrt, log, and exp (and all the others)?\n",
    "    Note: there are quite a few more of these questions on the project site we should answer.\n",
    " -->\n",
    " \n",
    " \n",
    " \n",
    "<!--\n",
    "-)\n",
    "-) Ok this is just me writing for ideas. We need a dual class, and maybe a function class? to read in the user input?\n",
    "-) For methods we will have: __add__, __sub__, __mul__, __div__, any others? For attributes we will have: __init__, derivative, seed_vector, variable?\n",
    "-) numpy, any others? (math, scipy, etc)\n",
    "-) like he did in class in the simple automatic differentiator, we should just manually define these ahead of time \n",
    "-->\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " <!-- consider a variety of use cases. For example, don't limit your design to scalar functions of scalar values. People may want to use it for Newton's method -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Licensing\n",
    "\n",
    " The MIT license is permissive and only requires the maintence of copyright and license notices. Unlike other licenses, no update notice is required. Automatic Differentiation is not a new method, thereby not needing a patent. Our library simply aims to make the user's project easier by importing a pre-defined solver rather than build one from scratch.\n",
    "\n",
    " The library and its usage comes as is, without warranty. Automatic differentiation is a mathematical solver, it is likely going to be embedded in a user's larger project, which is supported by this as well as its high license compatability. Limited restrictions on use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
