{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to our BAD (Basic Auto Differentiator) Package\n",
    "\n",
    "### Problem Description\n",
    "<!-- the problem the software solves -->\n",
    "This library solves the computational technique of automatic differentiation: a process to compute derivatives numerically within accurate machine approximation. This task is also called algorithmic differentiation, computational differentiation, auto-differentiation, or the acronym *AD*. The heart of AD lies in breaking down compounded functions to their basic components: arithmetic operations and elementary functions. The derivatives for these elementary functions are well known. Finally, the chain rule is applied to these operations and derivatives of any order can be computed.\n",
    "\n",
    "If complexity is low, a human can compute a derivative in one step using some memorized and nuanced rules. Often what is produced is *symbolic*, which is then evaluated for a numerical output for a given input. Computer cannot handle symbolic forms in the same way. They must either be given the values to make a direct computation, or the values that allow it to perform minor computations with those values and aggregate them with elementary operations like multiplication, division, addition, or subtraction. These are then compounded to form the overall derivative. While the approach is more sequential, the process is the same.\n",
    "\n",
    "### Motivations\n",
    "<!-- why it's important to solve that problem -->\n",
    "Many algorithms today are *optimizational*: aiming to solve a problem according to constraint(s) to the best of its ability. Optimization requires the use of such derivatives. When dealing with problems with more than one dimension, we must adapt the simple optimization problem into a multi-dimensional optimization problem. Minimizing the error of a function for *machine learning* frequently requires multi-dimensional optimization. Besides outperforming humans for complex functions, computers can also easily compute derivatives for 2-D `numpy` array inputs, outputting Jacobian matrices of results. Computationally intensive problems as listed below require derivatives within a larger pipeline, and must be self contained. AD is necessary for this purpose.\n",
    "\n",
    "- Generally used to model *1D flow* and *heat transfer* problems.\n",
    "- Generally used to optimize the *aerodynamic* properties of a body.\n",
    "- Problems in *physics* and *material science* requires the analysis of functions that rely on time, position, speed, and other problem-specific metrics.\n",
    "- *Adjoint Differentiation* in financial risk management is exactly this process.\n",
    "- Using *heuristic artificial intelligence methods* like *hill climbing* or *particle swarm* require the adjustment of -- for example purposes -- a ball dropped into a plane and moved in the direction that gets the ball to the target point the fastest. \n",
    "- Can solve *Ordinary Differential Equations* with a removable singularity.\n",
    "- *Neural networks* require the adjustment of a vector of weights per layer, therefore requiring us to optimize with respect to some standard (function).\n",
    "- NASA used AD for *computational fluid dynamics* with a larger goal of modeling flight and expected turbulence of a given space-craft design.\n",
    "- General Electric used AD to automate the study of *unexpected satellite motion* due to differences in Earth's gravitational flow.\n",
    "- Northwestern University published work on using AD as a framework to *reduce diffractions in microscopic imaging*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "<!-- (Brief) give the essential ideas of mathematical ideas and concepts (e.g. the chain rule, the graph structure of calculations, elementary functions, etc) -->\n",
    "\n",
    "Automatic differentiation computes the derivative of a function by solving it as a collection of the derivatives of its components. These individual components are elementary functions, connected by known, simple operators. The purpose behind this separation is that the individual functions can be easily solved using pre-established rules. The automatic differentiator can then solve any function made up of these components. \n",
    "\n",
    "### Elementary Functions\n",
    "Some examples of elementary functions include $e^x$, $\\log(x)$, $\\sin(x)$, and $\\cos(x)$. Some examples of elementary arithmetic operations include addition, subtraction, multiplication, and division. Automated differentiation uses the chain rule to split the given function into these elementary operators.\n",
    "\n",
    "### Derivatives\n",
    "A derivative describes the slope of a given function generally (produces another function denoted $f'$) or at a specific point by plugging in the value of interest into $f'$. In a general form, slopes tell us how much a response variable (usually $y$, which is often written as $f(x)$) changes when the input $x$ does. The best example of this concept is the equation of a line: $z = mx + b$, where $m$ is the slope. In this case, $m$ is a number. When we look at more complicated functions, the slope is often left in its functional representation $f'$ and used by plugging in a point later for the slope at a specific point.\n",
    "\n",
    "Slopes are the main component behind AD, since we are interested in how the given function behaves -- how our response variable changes -- as we \"look\" in isolated directions. If we have a function $f$ described by two variables $x, y$, we would want to compute two derivatives -- one *with respect* to $x$ while holding $y$ constant (think of it as just another number) and the other *with respect* to $y$ while holding $x$ constant. We can then answer the corresponding two questions of interest -- how much and in what way does the function $f$ change when $x$ does, and how much and in what way does the function $f$ change when $y$ does? \n",
    "\n",
    "### Chain Rule\n",
    "The chain rule applies to any elementary functions with variable input, which occurs often. We will be applying the chain rule repeatedly to our elementary operators. The chain rule can be further explored here.\n",
    "\n",
    "Suppose we have a function $g(f(x))$. Then, the derivative of this function will be\n",
    "\n",
    "$$\\frac{dg}{dx} = \\frac{dg}{df}\\frac{df}{dx}.$$\n",
    "\n",
    "Note that when functions have multiple arguments, $h(f(x), g(x))$, the chain rule can be applied like so\n",
    "\n",
    "$$\\frac{dh}{dx} = \\frac{dh}{df}\\frac{df}{dx} + \\frac{dh}{dg}\\frac{dg}{dx}.$$\n",
    "\n",
    "### Dual Numbers\n",
    "Another important component of automatic differentiation are dual numbers. Dual numbers have a real and dual component, expressed as $ z=a+b\\epsilon $. Here, $a$ is the real part, $b$ is the dual part, and $\\epsilon$ is a non-real number where $ \\epsilon^2=0 $ but $ \\epsilon \\neq 0 $. By using dual numbers in our auto differentiator, we can track both the function operations and their derivatives for each step as part of our data structure.\n",
    "\n",
    "### Forward Mode\n",
    "In a general sense, forward mode is an iterative evaluation of the chain rule. The evaluation trace is the outline of this path, step by step. At each step, we record the elementary operation, the directional derivative, and the output when solving for some value. For complex functions, computer numerical storage is beneficial because this method requires tracking all of these operations. Forward mode is most efficient when a potential function has significantly more outputs than inputs.\n",
    "\n",
    "### Reverse Mode\n",
    "In reverse automatic differentiation, we still separate the complex input function into the simpler, elementary functions. However, the chain rule pass begins at the end of the evaluation trace, and moves backwards through the steps of the function. Therefore, reverse mode contains two passes. First, a forward pass to calculate the primal trace. Second, a reverse pass to propagate backwards to the derivatives. When choosing between reverse and forward mode, it is important to keep in mind that if there are significantly more inputs than outputs, then reverse mode is more efficient. \n",
    "\n",
    "### Computational Graph and Trace Example\n",
    "<img src=\"./forward-mode-graph.jpg\" alt=\"Rough sketch of computational graph and traces. We will update a computer-generated plot in future milestones.\" />\n",
    "Figure: Rough sketch of computational graph and traces for a basic sample function. We will update a computer-generated plot in future milestones. \n",
    "\n",
    "\n",
    "\n",
    "<!-- \n",
    "Note: We should add a computation graph and notes about forward mode (and reverse mode?).\n",
    "Note: We should make a table(?) of all the accepted functions and their derivatives/how they will be used? ($ a+b $, $ a-b $, $ ab $, $ \\frac{a}{b} $, $ a^{b} $, $ sin(a) $, $ cos(a) $, $ tan(a) $, $ ln(a) $)\n",
    "\n",
    "dkim: added brief notes about elementary functions, i think we should add a forward mode/reverse mode section as well as computational graphs for each\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage Guide for the BAD Package\n",
    "\n",
    "<!-- How do you envision that a user will interact with your package? What should they import? How can they instantiate AD objects? -->\n",
    "\n",
    "### Installation\n",
    " A user can install the package with:\n",
    "\n",
    "``python -m pip install -i https://test.pypi.org/simple/ bad-package``\n",
    "\n",
    " Note: Our package will utilize NumPy.\n",
    "\n",
    "### Importing\n",
    " Once successfully installed, a user can import this package in their Python script like so:\n",
    "    \n",
    "``import bad-package as bad``\n",
    "\n",
    "#### Instantiating BAD Objects\n",
    " Here is a quick demo of how our BAD package can be used.\n",
    "```python\n",
    "# import our package:\n",
    "from bad-package.fad_package.fad import Forward\n",
    "from bad-package.rad_package.rad import Reverse\n",
    "\n",
    "# create a function to be evaluated at x=2:\n",
    "x = bad.DualNumber(real=2) \n",
    "my_fun = 2x+5\n",
    "\n",
    "# instantiate AD\n",
    "forward = Forward(my_fun, inputs)\n",
    "forward.get_value()\n",
    "\n",
    "reverse = Reverse(my_fun, inputs)\n",
    "reverse.get_value()\n",
    "\n",
    "# Jacobian\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Software Organization\n",
    "\n",
    "<!-- \n",
    "    What will the directory structure look like?\n",
    "    What modules do you plan on including? What is their basic functionality?\n",
    "    Where will your test suite live?\n",
    "    How will you distribute your package (e.g. PyPI with PEP517/518 or simply setuptools)?\n",
    "    Other considerations?\n",
    " -->\n",
    " \n",
    "### Directory Structure\n",
    "```\n",
    "|team23\n",
    "|—— docs\n",
    "|  |—— README.md\n",
    "|  |—— documentation\n",
    "|  |—— milestone1.ipynb\n",
    "|  |—— milestone2.ipynb\n",
    "|—— LICENSE\n",
    "|—— pyproject.toml\n",
    "|—— README.md\n",
    "|—— setup.cfg\n",
    "|—— src\n",
    "|  |—— bad_package\n",
    "|  |  |—— __init__.py\n",
    "|  |  |—— __main__.py\n",
    "|  |  |—— elementary_functions.py\n",
    "|  |  |—— fad_subpackage\n",
    "|  |  |  | __init__.py\n",
    "|  |  |  | __fad.py\n",
    "|  |  |—— rad_subpackage\n",
    "|  |  |  | __init__.py\n",
    "|  |  |  | __rad.py\n",
    "|——tests\n",
    "|  |—— test.txt\n",
    "|  |—— test_fad.py\n",
    "|  |—— test_rad.py\n",
    "```\n",
    "### Modules\n",
    "<!-- \n",
    "Note: What modules do you plan on including? What is their basic functionality?\n",
    " -->\n",
    "\n",
    "#### `ad_package`\n",
    "- `__init__`.py\n",
    "    - Initializing the package whenever package or module within the package is being imported. \n",
    "- `__main__.py`\n",
    "    - This file is the environment where top-level code is run, and it is executed by the interpreter whenever -m is passed. The `ad_package` `__main__.py` can be executed using `python -m ad_package`. \n",
    "- `elementary_functions.py`\n",
    "    - This file is where all the function overloads that are not linear will live, such as exponential, cosine, sine, tangent, pi, and natural log.\n",
    "\n",
    "#### `fad_subpackage`\n",
    "- `__init__.py`\n",
    "    - Initializing the subpackage whenever this subpackage or modules within this subpackage is being imported. \n",
    "\n",
    "- `__fad__.py`\n",
    "\n",
    "#### `rad_subpackage`\n",
    "- `__init__.py`\n",
    "    - Initializing the subpackage whenever this subpackage or modules within this subpackage is being imported. \n",
    "- `__rad__.py`\n",
    "\n",
    "#### `tests`\n",
    "- `test_fad.py`\n",
    "- `test_rad.py`\n",
    " \n",
    "### Tests\n",
    "The test suite will be located in the tests directory in the package's root directory.\n",
    "\n",
    "### Distribution\n",
    "The package will be distributed using the Python Package Index, `PyPI`. It will also be available to be cloned through our `team23` [GitHub repository](https://code.harvard.edu/CS107/team23)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation\n",
    " <!-- \n",
    "    What are the core data structures?\n",
    "    What classes will you implement?\n",
    "    What method and name attributes will your classes have?\n",
    "    What external dependencies will you rely on?\n",
    "    How will you deal with elementary functions like sin, sqrt, log, and exp (and all the others)?\n",
    "    Note: there are quite a few more of these questions on the project site we should answer.\n",
    " -->\n",
    "\n",
    "### Dependent and General Core Structures\n",
    "- Python Types: `int`, `float`, `string`, `list`\n",
    "- Numpy: `array`\n",
    " \n",
    "### Implemented Classes and Methods\n",
    "Anything not implemented throughout development will `raise NotImplementedError(\"Feature not implemented yet\")` with specific function name to tell the development team there is no functionality included, intentional or not. Some have `pass` listed here, since they are required, such as `__init__` and `__repr__`. Some functionality is shared between Forward and Reverse mode auto-differentiation, and may be abstracted to another module later in development provided sufficient substance.\n",
    "\n",
    "- Forward\n",
    "   ```python\n",
    "   def __init__(self, func, inputs):\n",
    "      self.func = func\n",
    "      self.inputs = inputs\n",
    "   def jacobian(self):\n",
    "      return np.array([self.z1.real, self.z1.dual], [self.z2.real, self.z2.dual])\n",
    "\n",
    "   ```\n",
    "- Reverse \n",
    "   ```python\n",
    "   def __init__(self, func, inputs):\n",
    "       self.func = func\n",
    "       self.inputs = inputs\n",
    "   def jacobian(self):\n",
    "       return np.array([self.z1.real, self.z1.dual], [self.z2.real, self.z2.dual]\n",
    "\n",
    "   ``` \n",
    "- DualNumber\n",
    "   ```python\n",
    "   def __init__(self, real, dual = 1.0):\n",
    "      self.real = real\n",
    "      self.dual = dual\n",
    "\n",
    "   def __add__(self, other):\n",
    "      # Addition of other DualNumbers, float, or int\n",
    "      raise NotImplementedError(\"Feature not implemented yet\")\n",
    "\n",
    "   def __radd__(self, other):\n",
    "      # Reverse addition of other DualNumbers, float, or int\n",
    "      raise NotImplementedError(\"Feature not implemented yet\")\n",
    "\n",
    "   def __sub__(self, other):\n",
    "      # Subtraction of other DualNumbers, float, or int\n",
    "      raise NotImplementedError(\"Feature not implemented yet\")\n",
    "\n",
    "   def __rsub__(self, other):\n",
    "      # Reverse subtraction of other DualNumbers, float, or int\n",
    "      raise NotImplementedError(\"Feature not implemented yet\")\n",
    "\n",
    "   def __mul__(self, other):\n",
    "      # Multiplication of other DualNumbers, float, or int\n",
    "      raise NotImplementedError(\"Feature not implemented yet\")\n",
    "\n",
    "   def __rmul__(self, other):\n",
    "      # Reverse multiplication of other DualNumbers, float, or int\n",
    "      raise NotImplementedError(\"Feature not implemented yet\")\n",
    "\n",
    "   ```\n",
    "\n",
    "- elementary_functions.py\n",
    "   ```python\n",
    "   def cos(x):\n",
    "      If isinstance(x, DualNumber):\n",
    "         raise NotImplementedError(\"Feature not implemented yet\")\n",
    "      elif isinstance(x, (float, int)):\n",
    "         return np.cos(x)\n",
    "      else:\n",
    "         raise TypeError(“Not Dual, float, int type”)\n",
    "   \n",
    "    def sin(x):\n",
    "      If isinstance(x, DualNumber):\n",
    "         raise NotImplementedError(\"Feature not implemented yet\")\n",
    "      elif isinstance(x, (float, int)):\n",
    "         return np.sin(x)\n",
    "      else:\n",
    "         raise TypeError(“Not Dual, float, int type”)\n",
    "    def tan(x):\n",
    "        if isinstance(x, DualNumber):\n",
    "            raise NotImplementedError(\"Feature not implemented yet\")\n",
    "        elif isinstance(x, (float, int)):\n",
    "            return np.tan(x)\n",
    "        else:\n",
    "            raise TypeError(“Not Dual, float, int type”)\n",
    "\n",
    "    def exp(x):\n",
    "        If isinstance(x, DualNumber):\n",
    "            raise NotImplementedError(\"Feature not implemented yet\")\n",
    "        elif isinstance(x, (float, int)):\n",
    "            return np.exp(x)\n",
    "        else:\n",
    "            raise TypeError(“Not Dual, float, int type”)\n",
    "\n",
    "    def log(x):\n",
    "        If isinstance(x, DualNumber):\n",
    "            raise NotImplementedError(\"Feature not implemented yet\")\n",
    "        elif isinstance(x, (float, int)):\n",
    "        \treturn np.log(x)\n",
    "        else:\n",
    "            raise TypeError(“Not Dual, float, int type”)\n",
    "    ```\n",
    "  \n",
    "  \n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "### Other Methods and Name Attributes \n",
    "We also expect to be using variables to store problem specific numbers. Appropriate getters and setters will be implemented as we go.\n",
    "\n",
    "- `derivative` -- current derivative\n",
    "- `seed vector` -- likely being set internally using DualNumber rather than stored\n",
    "- `output` -- final value output by `Reverse` and `Forward`\n",
    "- `derivatives` -- `np.array(derivative)`\n",
    "- `func` -- stored function passed from the user\n",
    "- `inputs` -- variables impacting functional output\n",
    "\n",
    "### Basic Operator Overloading/Elementary Functions\n",
    "- For all `numpy` functions or constants, we will rewrite and manually solve them so the user doesn’t have to use `np.<function or constant>`.\n",
    "- We will overload our basic operators to solve for the derivative of real and dual components and to work with each method listed above\n",
    "\n",
    "### Library Dependence\n",
    "- `Numpy`\n",
    "   - $ sin $, $ cos $, $ tan $, $e$, $\\pi$\n",
    "\n",
    " \n",
    "<!--\n",
    "-)\n",
    "-) Ok this is just me writing for ideas. We need a dual class, and maybe a function class? to read in the user input?\n",
    "-) For methods we will have: __add__, __sub__, __mul__, __div__, any others? For attributes we will have: __init__, derivative, seed_vector, variable?\n",
    "-) numpy, any others? (math, scipy, etc)\n",
    "-) like he did in class in the simple automatic differentiator, we should just manually define these ahead of time \n",
    "-->\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " <!-- consider a variety of use cases. For example, don't limit your design to scalar functions of scalar values. People may want to use it for Newton's method -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Licensing\n",
    "\n",
    " The MIT license is permissive and only requires the maintenance of copyright and license notices. Unlike other licenses, no update notice is required. Automatic Differentiation is not a new method, thereby not needing a patent. Our library simply aims to make the user's project easier by importing a pre-defined solver rather than build one from scratch.\n",
    "\n",
    " The library and its usage comes as is, without warranty. Automatic differentiation is a mathematical solver, it is likely going to be embedded in a user's larger project, which is supported by this as well as its high license compatibility. Limited restrictions on use. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedback\n",
    "### Introduction (2/2)\n",
    "Good! I found it to be a little unstructured (alternating between pros and cons of using computers for differentiation in the, e.g.)\n",
    "The part on motivations was a little sparse, missing some use cases beyond that neural nets use it.\n",
    "- Reduced Problem Description. Moved some parts to Motivations.\n",
    "- Focused on transition from definition > how humans create symbolic derivatives > computers need numerics for computation > AD breaks it down so the computer can store it > these are equivalent.\n",
    "- Motivations talk about optimization > relation to derivatives and AD > why we can't rely on humans to do derivatives all the time > a list of applications from most general to most specific.\n",
    "\n",
    "### Background (2/2)\n",
    "Very good!\n",
    "A few comments:\n",
    "A little wordy, documentation should be terse and to the point\n",
    "a little confusing that the variable y was reused in two separate uses\n",
    "- Shortened background section a little bit and created new variable in our example so all variables are now unique.\n",
    "\n",
    "### How to use (3/3)\n",
    "Good!\n",
    "One question:\n",
    "Is implementing functions as strings like \"2*x+5\" the best way? Will you write a parser for arbitrary expressions, or is it better with a function class that handles this?\n",
    "- Instead of instantiating our function as a string, we will be using our DualNumbers class to create variables. Moreover, we will be creating an elementary function module that handles the different functions that we will implement in our package.\n",
    "\n",
    "### Software organization (2/2)\n",
    "Good! Think about where the tests will live and what will be a package and module, i.e., what folders will have init files and where you can import stuff from in the different modules.\n",
    "- Added elementary_functions.py into directory structure\n",
    "\n",
    "### Implementation (3/4)\n",
    "Good, but missing some details about the actual implementation of forward/backward and how the function the user specificies is handled.\n",
    "Comments\n",
    "No need to spell out the str and repr dunder methods in the document as these are assumed to always be present\n",
    "Should explicitly specify what you anticipate the Jacobian class to take in init\n",
    "How are you dealing with function overloads, i.e., what happens when you are using functions that are not just linear in x like the exponential or cosine?\n",
    "\n",
    "Our changes:\n",
    "- User should instantiate a DualNumber for any variable used in function to be derived\n",
    "- Removed str and repr dunder methods\n",
    "- Jacobian method nested in Forward and Backwards classes which will operate on the self stored DualNumber objects\n",
    "- Making a module called elementary_functions.py that contains our overloaded defined functions. Functions that users would want to use that are not in our class will throw an error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "472e01e86847e4e8d5702885b2eb2ce735152928be6d128b91f2735c8864fa00"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
